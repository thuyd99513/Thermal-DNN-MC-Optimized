# Manus AI 继续开发指南

本项目已由 Manus AI 完成了核心优化工作。本指南旨在帮助后续的 Manus AI 实例快速理解项目现状并继续开发。

## 当前状态 (2026-01-27)

- **核心优化已完成**：实现了 `Network_optimized_v3.py`，其中自旋 (S) 和权重 (J) 的更新均已实现完全向量化和 Numba JIT 加速。
- **性能达标**：完整 MC 步的加速比在典型配置下达到了 **37x - 95x**。
- **正确性已验证**：通过了严格的单元测试，确保能量计算与原始串行实现一致。

## 已完成的工作

1. **S 更新优化 (V2)**：利用同层自旋无耦合的物理特性，实现 $M \times N$ 规模的并行更新。
2. **J 更新优化 (V3)**：实现按行并行的权重更新，处理了关键的 `rescale` 归一化逻辑。
3. **自动化测试**：建立了正确性验证 (`test_J_correctness.py`) 和性能基准测试体系 (`benchmark_full_mc.py`)。
4. **详细报告**：在 `reports/` 目录下记录了每一阶段的优化细节和性能数据。

## 建议的后续任务

如果您是新接入的 Manus AI，可以考虑以下方向：

### 1. 进一步性能优化
- **GPU 加速**：目前的优化基于 CPU (Numba/NumPy)。可以尝试使用 `CuPy` 或 `PyTorch` 将计算迁移到 GPU，预期可获得 100x 以上的进一步加速。
- **多线程优化**：进一步调整 Numba 的 `parallel=True` 参数，优化在大规模网络下的多核利用率。

### 2. 功能扩展
- **支持更多势能函数**：目前仅支持软核势能，可以扩展支持其他物理模型。
- **自动化调参**：实现自动化的 $\beta$ (逆温度) 扫描和相变点检测。

### 3. 数据分析与可视化
- **实时能量监控**：开发一个实时显示能量演化和自旋状态的仪表盘。
- **分层结构分析**：编写脚本自动分析并可视化"固-液-固"分层现象。

## 给 Manus 的提示

- **环境准备**：确保安装了 `numba` (`pip install numba`)。
- **JIT 预热**：在运行正式模拟前，务必调用 `warmup_jit()` 以避免初次编译带来的延迟。
- **参考文档**：优先阅读 `reports/J_optimization_report.md` 了解最新的技术细节。

---

## 附录：历史文档 (V1/V2)

### 关键文件说明

| 文件 | 说明 | 状态 |
|------|------|------|
| `py_functions/Network.py` | 原始实现 | 参考 |
| `py_functions/Network_optimized_v2.py` | 仅优化 S 更新的版本 | 稳定 |
| `py_functions/Network_optimized_v3.py` | S 和 J 均优化的版本 ⭐ | **推荐使用** |

### 能量计算详解

#### 软核势能函数
当 gap `h < 0` 时，系统受到惩罚（能量增加）：$V(h) = h^2$。

#### Part Gap 方法
当自旋 `S[mu, l, n]` 翻转时，只有 **N+1 个 gap** 受影响。
当权重 `J[n2, n1]` 更新时，受影响的是该行对应的 **M 个样本的 gap**。
